{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNI42UrLsiZk",
        "outputId": "12613b2b-f8e6-4de6-d286-5618a4165fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "JpsfgH7myHZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhH8Dw7hw1-s",
        "outputId": "369ad263-510b-4211-acaf-020291a153e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API key:路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "#Model A: The \"Accountant\" (Precision)\n",
        "llm_focused = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)\n",
        "\n",
        "#Modek B: The\n",
        "llm_creative = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=1.0)"
      ],
      "metadata": {
        "id": "acHMY54MymhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Define the word 'Idea' in one sentence.\"\n",
        "\n",
        "print(\"--- FOCUSED (Temp=0) ---\")\n",
        "print(f\"Run 1: {llm_focused.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_focused.invoke(prompt).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyTrMlw-y4IV",
        "outputId": "9d1b0e0b-1751-44ca-bf15-462eccf0e1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- FOCUSED (Temp=0) ---\n",
            "Run 1: An idea is a thought, concept, or mental image formed in the mind.\n",
            "Run 2: An idea is a thought, concept, or suggestion that is formed or exists in the mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Define the word 'Idea' in one sentence.\"\n",
        "\n",
        "print(\"--- creative (Temp=1) ---\")\n",
        "print(f\"Run 1: {llm_focused.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_focused.invoke(prompt).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O588k5dhzmo3",
        "outputId": "d59ece36-0941-4616-c008-476bb43e0f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- creative (Temp=1) ---\n",
            "Run 1: An idea is a thought, concept, or suggestion that is formed or exists in the mind.\n",
            "Run 2: An idea is a thought, concept, or suggestion that is formed or exists in the mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup from Part 1a (Hidden for brevity)\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key:\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "CDGvBqYrzw7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) **Strings vs. Messages**"
      ],
      "metadata": {
        "id": "rCaR9L3ucEtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a highly educated person. You use big words to explain any answer\"),\n",
        "    HumanMessage(content=\"What is the best dessert?\")\n",
        "]\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WXONpjezyvP",
        "outputId": "73b90055-b459-4d75-ae14-ca429f69c076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To adjudicate a singular \"best\" dessert is to embark upon a Sisyphean task, for the very notion of culinary supremacy is inextricably tethered to the idiosyncratic predilections of the individual palate and the kaleidoscopic tapestry of cultural and gastronomic heritage. A definitive declaration would be an exercise in utter futility, an arbitrary imposition upon the vast panorama of human gustatory experience.\n",
            "\n",
            "Rather than pinpointing a solitary confection, it is more judicious to delineate the *characteristics* that elevate a dessert from mere sustenance to an apotheosis of culinary artistry and sensory delight. An truly exceptional dessert is a symphony of harmonious elements: a meticulously calibrated saccharine equilibrium that avoids cloying excess, a textural interplay that provides both counterpoint and cohesion (perhaps the ethereal lightness of a mousse juxtaposed with the delicate crispness of a tuile, or the tender yielding of a cr猫me br没l茅e beneath a brittle, caramelized edifice), and an aromatic profile that tantalizes the olfactory senses before the first morsel even graces the tongue.\n",
            "\n",
            "Furthermore, the *context* is paramount. For one, the sublime simplicity of a perfectly ripe fruit, perhaps accompanied by a whisper of Chantilly cream, might be the epitome of refreshment after a rich repast. For another, the intricate architecture of a multi-layered entremet, demanding hours of meticulous craftsmanship, represents the zenith of patisserie. One might find profound solace in the comforting familiarity of a homemade apple crumble, redolent with cinnamon and butter, while another seeks the exotic allure of a meticulously crafted mochi or the sophisticated bitterness of a dark chocolate lava cake with a molten core.\n",
            "\n",
            "Ultimately, the \"best\" dessert is a profoundly personal revelation, an ephemeral pleasure that resonates most deeply with one's own memories, desires, and cultivated tastes. It is not an objective truth to be discovered, but a subjective rapture to be experienced, a confluence of impeccable ingredients, artful execution, and the unique receptivity of the consumer. It is the dessert that, in that particular moment, transcends the mundane and evokes a genuine, unadulterated sense of epicurean bliss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"]=getpass.getpass(\"Enter your Google API Key:\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "template = ChatPromptTemplate.from_template(\"Tell me a fun fact about {topic}\")\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "JMhFCske1Bke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value = template.invoke({\"topic\": \"crows\"})\n",
        "response_obj = llm.invoke(prompt_value)\n",
        "final_text = parser.invoke(response_obj)\n",
        "print(final_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMM7JI3o1zcG",
        "outputId": "3762ab31-e8a6-4dcb-bbdf-69b42977639b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun one:\n",
            "\n",
            "Crows are incredibly intelligent and can actually **recognize and remember individual human faces!** Not only that, but they can teach other crows about \"bad\" humans (or good ones!), and they've been known to hold a grudge against specific people for *years*. So, be nice to your local crows! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = template | llm | parser\n",
        "print(chain.invoke({\"topic\": \"the color pink\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OQrIxz-2vrW",
        "outputId": "26d24f86-4d8f-41d6-f718-82ddb6642698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun one:\n",
            "\n",
            "For a long time, **pink was actually considered a masculine color, often associated with boys!**\n",
            "\n",
            "Think about it this way: red was a powerful, strong color, and pink was seen as a lighter, more assertive version of red. Blue, conversely, was often associated with girls because it was seen as more delicate and ethereal.\n",
            "\n",
            "The whole \"pink for girls, blue for boys\" thing only really became cemented in the mid-20th century. Before that, it was common to see boys dressed in pink and girls in blue!\n"
          ]
        }
      ]
    }
  ]
}